{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last updated: 2020-06-06 \n",
      "\n",
      "numpy 1.18.4\n",
      "pandas 1.0.4\n",
      "matplotlib 3.2.1\n",
      "sklearn 0.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -u -d -p numpy,pandas,matplotlib,sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** 코딩해야할 부분을 제외하고는 수정하지 마세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_sci = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train_, y_test_ = train_test_split(mnist_sci.data, mnist_sci.target, \n",
    "                                                    test_size = 0.1,\n",
    "                                                   shuffle = True)\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "\n",
    "def one_hoy_label(X):\n",
    "    T = np.zeros((X.size, 10))    \n",
    "    for idx, row in enumerate(T):\n",
    "        row[int(X[idx])] = 1\n",
    "        \n",
    "    return T\n",
    "\n",
    "y_train = one_hoy_label(y_train_)\n",
    "y_test = one_hoy_label(y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nN = 4\\nM = 10\\nfig = plt.figure(figsize=(10, 5))\\nplt.subplots_adjust(top=1, bottom=0, hspace=0, wspace=0.05)\\nfor i in range(N):\\n    for j in range(M):\\n        k = i*M+j\\n        ax = fig.add_subplot(N, M, k+1)\\n        ax.imshow(x_train[k].reshape(28,28), cmap=plt.cm.bone, interpolation=\"none\")\\n        ax.grid(False)\\n        ax.xaxis.set_ticks([])\\n        ax.yaxis.set_ticks([])\\n        plt.title(y_train_[k])\\nplt.tight_layout()\\nplt.show()\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "N = 4\n",
    "M = 10\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.subplots_adjust(top=1, bottom=0, hspace=0, wspace=0.05)\n",
    "for i in range(N):\n",
    "    for j in range(M):\n",
    "        k = i*M+j\n",
    "        ax = fig.add_subplot(N, M, k+1)\n",
    "        ax.imshow(x_train[k].reshape(28,28), cmap=plt.cm.bone, interpolation=\"none\")\n",
    "        ax.grid(False)\n",
    "        ax.xaxis.set_ticks([])\n",
    "        ax.yaxis.set_ticks([])\n",
    "        plt.title(y_train_[k])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax_CE:\n",
    "    \"\"\"\n",
    "    편의를 위해서 softmax와 crossenropy를 결합한 것입니다.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.loss = None # 손실함수\n",
    "        self.y = None    # softmax의 출력\n",
    "        self.t = None    # 정답 레이블(원-핫 인코딩 형태)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = CE_loss(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \n",
    "    ######################################################################\n",
    "    # 문제 1-1 softmax 함수를 구현하세요                                 #\n",
    "    ######################################################################\n",
    "   # softmax의 지수가 커질 수록 매우 큰 폭으로 증가하기 때문에 overflow가 발생하기 쉽다.\n",
    "    x = x.T\n",
    "    exp_x = np.exp(x- np.max(x,axis=0)) # 각각의 원소에 최댓값을 뺀 값에 exp를 취한다. (이를 통해 overflow 방지)\n",
    "    sum_exp_x = np.sum(exp_x,axis=0) # 평균을 위한 각 output의 exp결과를 모두 더함\n",
    "    y = exp_x / sum_exp_x # softmax\n",
    "    ######################################################################\n",
    "    #                          END OF YOUR CODE                          #\n",
    "    ######################################################################\n",
    "    return y.T # y,T는 transpose를 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ CE = \\frac{1}{N_{batch}} \\sum(log(y, t))$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE_loss(y, t):\n",
    "    \n",
    "    ######################################################################\n",
    "    # 문제 1-2 cross entropy 함수를 구현하세요.                               \n",
    "    # y 값의 경우 예측한 값, t값의 경우 true label 값입니다.    \n",
    "    # batch 로 데이터가 들어온다는 것을 유의 하세요.\n",
    "    ######################################################################\n",
    "    if y.ndim == 1: # reshape 필요 (3,) -> (1,3)\n",
    "        t = t.reshape(1,-1)\n",
    "        y = y.reshape(1,-1)\n",
    "    delta = 1e-7 # y가 0이면 로그가 -무한대로 가기때문에 그것을 방지하기 위해 아주 작은 값을 더해줌\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y+delta) * t) / batch_size # 평균을 내기위해 batch size로 나눠줌\n",
    "    ######################################################################\n",
    "    #                          END OF YOUR CODE                          #\n",
    "    ######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    ######################################################################\n",
    "    # 문제 1-3 Rely layer 를 구현하세요                                  #\n",
    "    # 출력값이 0이 되는 부분과 아닌 부분에 대해서 잘 생각해보세요        #\n",
    "    ######################################################################\n",
    "    \n",
    "    # masking을 해보세요\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0) # ReLu의 정의에 따르면, x<=0일 때, mask false, x>0일 때, mask ture\n",
    "        out = x.copy() # relu의 결과를 저장할 out배열\n",
    "        out[self.mask] = 0 # 마스킹 된것 필터링\n",
    "        return out # 필터링 결과\n",
    "\n",
    "    # 항등항수의 미분은 자기 자신입니다. \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0 # forward의 x값이 역전파의 Relu통과 기준이므로, 이전에 지정했던 mask이용해서  true면 역전파 통과, false면 역전파 필터링\n",
    "        dx = dout # 미분의 결과배열이 dout임\n",
    "        return dx # 미분 결과 리턴 gradient 누적\n",
    "    \n",
    "    ######################################################################\n",
    "    #                          END OF YOUR CODE                          #\n",
    "    ######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FClayer:\n",
    "    ######################################################################\n",
    "    # 문제 1-4 fully connecter layer 를 완성하세요                       #\n",
    "    # 행렬의 곱셈에 대한 backward를 신중히 구현하세요                    #\n",
    "    ######################################################################\n",
    "    def __init__(self, W, b):\n",
    "        \n",
    "        self.W = W # 가중치 배열\n",
    "        self.b = b # bais\n",
    "        \n",
    "        self.x = None # input\n",
    "        \n",
    "        # backward 를 위해서 shape을 변경할 수가 있어서 원래의 shape 저장\n",
    "        self.original_x_shape = None\n",
    "        \n",
    "        # 가중치와 편향 매개변수의 미분\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 본인이 구현한 입력 이미지의 shape 에 따라서 조정을 해줄수도 있습니다. \n",
    "        self.original_x_shape = x.shape # 행렬미분에서 차원변환이 일어나기에 이 값을 알나와야 역전파에 사용할 수 있다.\n",
    "        self.x = x\n",
    "        out = np.dot(self.x,self.W) + self.b # weight matrix와 feature벡터 내적(곱이지만, x가 1차원이므로 내적과 다를 것 없다.) + bias 더하기\n",
    "        return out\n",
    "    \n",
    "    # 1차원 함수의 곱셈에 대해서 생각해보고 그것을 확장하세요 \n",
    "    # 항상 데이터의 shape에 주의 하세요\n",
    "    # chain rule for update weight matrix\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T) # 행렬을 행렬로 미분하면 전치행렬이 나온다 ## 선형대수\n",
    "        self.dW = np.dot(self.x.T, dout) # 행렬을 행렬로 미분하면 전치행렬이 나온다 ## 선형대수\n",
    "        self.db = np.sum(dout, axis=0) # W벡터에 W0가 N개 추가되는 거니까 다음 레이어에 W0*N만큼 영향을 끼침 \n",
    "        dx = dx.reshape(*self.original_x_shape) # backward 를 위해서 shape을 변경  행렬 미분에서 transpose가 일어나므로, 모양을 변경\n",
    "        return dx    \n",
    "    ######################################################################\n",
    "    #                          END OF YOUR CODE                          #\n",
    "    ######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transpose shape :  (3, 2)\n",
      "original shape (2, 3)\n"
     ]
    }
   ],
   "source": [
    "# reshape 공부\n",
    "b = np.array([[7,8,9],[10,11,12]])\n",
    "origin_shape = b.shape\n",
    "b = b.T # 3X2\n",
    "print('transpose shape : ', b.shape)\n",
    "b = b.reshape(*origin_shape) # reshape에서 *의 역할은 tuple형태의 shape 데이터를 받아 그 모양으로 복구\n",
    "print('original shape', b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이번 과제의 네트워크의 구조는 1개의 히든 레이어를 가진 네트워크 입니다.\n",
    "#### 활성함수로는 Relu 를 사용하세요 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        \n",
    "        ######################################################################\n",
    "        # 문제 1-5 파라미터 초기화를 적용하세요                              #\n",
    "        # 최소한 85% 이상의 test acc가 나올수 있도록 하세요                  #\n",
    "        # 수업시간에 배운 초기화 방법이 성능이 보통 좋습니다. \n",
    "        # 파라미터의 shape에 대해 잘 생각해보세요\n",
    "        ######################################################################\n",
    "\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size) # 가중치 행렬 초기화\n",
    "        self.params['b1'] = np.full(hidden_size,0.5) # bias초기화 무난 하게 정규분포의 평균으로 시작해봄\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) # 가중치 행렬 초기화\n",
    "        self.params['b2'] = np.full(output_size,0.5)\n",
    "        \n",
    "        ######################################################################\n",
    "        #                          END OF YOUR CODE                          #\n",
    "        ######################################################################\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['FClayer1'] = FClayer(self.params['W1'], self.params['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['FClayer2'] = FClayer(self.params['W2'], self.params['b2'])\n",
    "\n",
    "        self.lastLayer = Softmax_CE()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)        \n",
    "        return x\n",
    "        \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "       \n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['FClayer1'].dW, self.layers['FClayer1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['FClayer2'].dW, self.layers['FClayer2'].db\n",
    "\n",
    "        return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\ttest acc  \n",
      "    0\t0.9083\n",
      "    1\t0.9276\n",
      "    2\t0.9396\n",
      "    3\t0.9471\n",
      "    4\t0.9529\n",
      "    5\t0.9569\n",
      "    6\t0.9591\n",
      "    7\t0.9623\n",
      "    8\t0.9636\n",
      "    9\t0.9654\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################################################################\n",
    "# 문제 1-6 구현한 것을 바탕으로 최종적으로 학습해보세요              #\n",
    "# 최소한 85% 이상의 test acc가 나올수 있도록 하세요                  #\n",
    "# 보고서에 print 값과 그래프를 제출하세요                            #\n",
    "######################################################################\n",
    "\n",
    "network = DNN(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100   \n",
    "learning_rate = 0.1\n",
    "\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "epochs = 10\n",
    "step = int(train_size / batch_size)\n",
    "\n",
    "print('{:<5}\\t{:<10}'.format('epoch', 'test acc'))\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx in range(step):\n",
    "        x_batch = x_train[batch_idx*batch_size:batch_idx*batch_size+batch_size]\n",
    "        y_batch = y_train[batch_idx*batch_size:batch_idx*batch_size+batch_size]\n",
    "        \n",
    "        grad = network.gradient(x_batch,y_batch)\n",
    "\n",
    "\n",
    "        # 매개변수 갱신\n",
    "        for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "            network.params[key] -= learning_rate * grad[key]\n",
    "\n",
    "        # 학습 경과 기록\n",
    "        loss = network.loss(x_batch,y_batch)\n",
    "\n",
    "\n",
    "    train_acc = network.accuracy(x_train,y_train)\n",
    "    test_acc = network.accuracy(x_test,y_test)\n",
    "    train_acc_list.append(train_acc)\n",
    "    test_acc_list.append(test_acc)\n",
    "    print('{:5}\\t{:.4f}'.format(epoch, test_acc))\n",
    "\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
