{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:54:48.508891Z",
     "start_time": "2020-06-07T06:54:48.247497Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last updated: 2020-06-25 \n",
      "\n",
      "numpy 1.18.4\n",
      "pandas 1.0.4\n",
      "matplotlib 3.2.1\n",
      "sklearn 0.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -u -d -p numpy,pandas,matplotlib,sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** 코딩해야할 부분을 제외하고는 수정하지 마세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:55:03.109724Z",
     "start_time": "2020-06-07T06:54:49.615474Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist_sci = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:55:03.494027Z",
     "start_time": "2020-06-07T06:55:03.117550Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train_, y_test_ = train_test_split(mnist_sci.data, mnist_sci.target, \n",
    "                                                    test_size = 0.1,\n",
    "                                                   shuffle = True)\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "x_train = x_train.reshape(-1,1,28,28)\n",
    "x_test = x_test.reshape(-1,1,28,28)\n",
    "\n",
    "def one_hoy_label(X):\n",
    "    T = np.zeros((X.size, 10))    \n",
    "    for idx, row in enumerate(T):\n",
    "        row[int(X[idx])] = 1\n",
    "        \n",
    "    return T\n",
    "\n",
    "y_train = one_hoy_label(y_train_)\n",
    "y_test = one_hoy_label(y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax_CE:\n",
    "    \"\"\"\n",
    "    편의를 위해서 softmax와 crossenropy를 결합한 것입니다.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.loss = None # 손실함수\n",
    "        self.y = None    # softmax의 출력\n",
    "        self.t = None    # 정답 레이블(원-핫 인코딩 형태)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = CE_loss(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 1 에서 구현한 것을 바탕으로 CNN도 적용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None  \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        self.mask = (x <= 0)   \n",
    "        out = x.copy()  \n",
    "        out[self.mask] = 0\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    # 항등항수의 미분은 자기 자신입니다. \n",
    "    def backward(self, dout):\n",
    "        \n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "\n",
    "        return dx      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FClayer:\n",
    "    def __init__(self, W, b):\n",
    "        \n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        \n",
    "        self.x = None\n",
    "        \n",
    "        # backward 를 위해서 shape을 변경할 수가 있어서 원래의 shape 저장\n",
    "        self.original_x_shape = None\n",
    "        \n",
    "        # 가중치와 편향 매개변수의 미분\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 본인이 구현한 입력 이미지의 shape 에 따라서 조정을 해줄수도 있습니다. \n",
    "        \n",
    "        self.original_x_shape = x.shape \n",
    "        self.x = x.reshape(x.shape[0],-1)\n",
    "        out = np.dot(self.x,self.W) + self.b \n",
    "        \n",
    "        return out\n",
    "    \n",
    "    # 1차원 함수의 곱셈에 대해서 생각해보고 그것을 확장하세요 \n",
    "    # 항상 데이터의 shape에 주의 하세요\n",
    "    def backward(self, dout):\n",
    "        #chain rule\n",
    "        dx = np.dot(dout, self.W.T) \n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0) \n",
    "        dx = dx.reshape(*self.original_x_shape)\n",
    "        return dx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \n",
    "    x = x.T\n",
    "    exp_x = np.exp(x- np.max(x,axis=0)) # 각각의 원소에 최댓값을 뺀 값에 exp를 취한다. (이를 통해 overflow 방지)\n",
    "    sum_exp_x = np.sum(exp_x,axis=0) # 평균을 위한 각 output의 exp결과를 모두 더함\n",
    "    y = exp_x / sum_exp_x # softmax\n",
    "    \n",
    "    return y.T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE_loss(y, t):\n",
    "    \n",
    "    if y.ndim == 1:\n",
    "        y = y.reshape(1, y.size)\n",
    "        t = t.reshape(1, t.size)\n",
    "\n",
    "    if y.size == t.size:\n",
    "        t = t.argmax(axis=1)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    \n",
    " \n",
    "    \n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv():\n",
    "    def __init__(self, W, b, stride=1, pad=0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None   \n",
    "        \n",
    "        # 가중치와 편향 매개변수의 기울기\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        \n",
    "        self.out_h = None\n",
    "        self.out_w = None\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # backward 의 shape 확인을 위해서 저장\n",
    "        self.x = x[:]        \n",
    "        \n",
    "        #C_ : filter 채널 수, FN : filter 개수 , FH : filter 행 수, FW : filter 열 수\n",
    "        #N : input 개수, C : input 채널 수, H: input 행 수, W : input 열 수\n",
    "        FN, C_, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        \n",
    "        # output 출력 shape \n",
    "        self.out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n",
    "        self.out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n",
    "        out_h = self.out_h\n",
    "        out_w = self.out_w        \n",
    "        \n",
    "        # padding\n",
    "        pad_x = np.pad(\n",
    "            x, \n",
    "            ((0, 0), (0, 0), (self.pad, self.pad), (self.pad, self.pad)), \n",
    "            \"constant\", constant_values=0\n",
    "        )\n",
    "        \n",
    "   \n",
    "        out = np.zeros((N, FN, out_h, out_w))        \n",
    "        for n in range(N):\n",
    "            for f in range(FN):\n",
    "                for j in range(out_h):\n",
    "                    for i in range(out_w):\n",
    "                        ######################################################################\n",
    "                        # 문제 2-1-1 forward를 구현 하세요                                   #\n",
    "                        ######################################################################\n",
    "                        \n",
    "                        \n",
    "                        out[n,f,j,i] = np.sum(pad_x[n,:,j * self.stride : j * self.stride + FH, i * self.stride : i * self.stride + FW] * self.W[f,:,:,:]) # 합성곱\n",
    "                        out[n,f,j,i] += self.b[f] # 편향 더하기\n",
    "                                                \n",
    "                        ######################################################################\n",
    "                        #                          END OF YOUR CODE                          #\n",
    "                        ######################################################################\n",
    "                        \n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        \n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = self.x.shape\n",
    "        \n",
    "        out_h = self.out_h\n",
    "        out_w = self.out_w\n",
    "        \n",
    "        # padding\n",
    "        pad_x = np.pad(\n",
    "            self.x, \n",
    "            ((0, 0), (0, 0), (self.pad, self.pad), (self.pad, self.pad)), \n",
    "            \"constant\", constant_values=0\n",
    "        )\n",
    "        \n",
    "        dx = np.zeros(pad_x.shape)\n",
    "        dw = np.zeros(self.W.shape)\n",
    "        db = np.zeros(self.b.shape)\n",
    "        \n",
    "    \n",
    "        for n in range(N):\n",
    "            for f in range(FN):\n",
    "                for j in range(out_h):\n",
    "                    for i in range(out_w):\n",
    "                        ######################################################################\n",
    "                        # 문제 2-1-2 backward 구현 하세요                                   #\n",
    "                        ######################################################################\n",
    "                        # dw dx서로 교차해서 전파 , 행렬 미분 & 곱 미분 -> dnn에서 했던 것과 동일\n",
    "                        dw[f,:,:,:] += pad_x[n,:,j * self.stride : j * self.stride + FH, i * self.stride : i * self.stride + FW ] * dout[n,f,j,i] \n",
    "                        dx[n, :, j * self.stride : j * self.stride + FH, i * self.stride : i * self.stride + FW] += self.W[f] * dout[n,f,j,i]\n",
    "                        db[f] = np.sum(dout[n, f , j , i ])\n",
    "                        ######################################################################\n",
    "                        #                          END OF YOUR CODE                          #\n",
    "                        ######################################################################\n",
    "                        \n",
    "        # remove padding\n",
    "        dx = dx[:, :, self.pad:dx.shape[2]-self.pad, self.pad:dx.shape[3]-self.pad]\n",
    "        \n",
    "        self.db = db\n",
    "        self.dW = dw\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x[:]\n",
    "        N, C, H, W = x.shape\n",
    "        \n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "        \n",
    "        \n",
    "        out = np.zeros((N, C, out_h, out_w))\n",
    "        for j in range(out_h):\n",
    "            for i in range(out_w):\n",
    "                ######################################################################\n",
    "                # 문제 2-2-1 forward를 구현 하세요                                   #\n",
    "                ######################################################################\n",
    "                # out은 입력이미지 100개(axis = 3), 필터 수(axis = 2)개 만큼 있고 각각의 것에서 최대 뽑아야함 \n",
    "                out[:, :, j, i] = np.max(self.x[:, :, j * self.stride: j * self.stride + self.pool_h, i * self.stride : i * self.stride + self.pool_w], \n",
    "                                         axis = (2,3))\n",
    "                \n",
    "                ######################################################################\n",
    "                #                          END OF YOUR CODE                          #\n",
    "                ######################################################################\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        \n",
    "        N, C, H, W = self.x.shape\n",
    "        out_h = (H-self.pool_h) // self.stride + 1\n",
    "        out_w = (W-self.pool_w) // self.stride + 1\n",
    "\n",
    "        dx = np.zeros(self.x.shape)\n",
    "        for n in range(N):\n",
    "            for c in range(C):\n",
    "                for j in range(out_h):\n",
    "                    for i in range(out_w):\n",
    "                        ######################################################################\n",
    "                        # 문제 2-2-2 backward를 구현 하세요                                   #\n",
    "                        ######################################################################\n",
    "                        # max 행렬 masking\n",
    "                        \n",
    "                        scan_for_mask = self.x[n, c, j * self.stride : j * self.stride + self.pool_h, i * self.stride : i * self.stride + self.pool_w] # 인풋에서 마스킹 할 구역\n",
    "                        \n",
    "                        mask = (scan_for_mask == np.max(scan_for_mask) )   # 마스킹 생성\n",
    "\n",
    "                        dx[n, c, j * self.stride : j * self.stride + self.pool_h, i * self.stride : i * self.stride + self.pool_w] =  mask * dout[n, c, j, i] # 필터링\n",
    "                        \n",
    "                        ######################################################################\n",
    "                        #                          END OF YOUR CODE                          #\n",
    "                        ######################################################################        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:55:19.163192Z",
     "start_time": "2020-06-07T06:55:19.146865Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleConvNet:\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        weight_init_std = 0.01\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        \n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        \n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "        \n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Conv(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = MaxPooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['FClayer1'] = FClayer(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['FClayer2'] = FClayer(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = Softmax_CE()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        ######################################################################\n",
    "        #  2-3 해당 주어진 gradient 함수에 주석을 다세요                     #\n",
    "        ######################################################################\n",
    "        \n",
    "        # forward\n",
    "        self.loss(x, t) # cross - entropy loss function\n",
    "     \n",
    "        # backward\n",
    "        dout = 1 # cross - entropy의 역전파 시작은 1, cross - entropy를 미분하면\n",
    "        # y는 원 핫 인코딩 형태의 벡터의 원소 즉 [0,0,1,0]... 이런형태, i는 분류되는 클래스 중 하나\n",
    "        ############# \n",
    "        # |ㅡ 1 (y == i)\n",
    "        # |\n",
    "        # |ㅡ 0 (otherwise)\n",
    "        #############\n",
    "        # 각 클래스의 가중치가 업데이트 돼야 하는 과정이므로 1이라는 스칼라가 들어가서 가중치 업데이트를 시작합니다.\n",
    "        # 0이 들어간다면 파라미터 업데이트가 진행되지 않습니다.\n",
    "        dout = self.last_layer.backward(dout) # softmax와 cross entropy의 역전파 시작 |softmax layer| <-----| cross entropy layer |<---1 \n",
    "        # cross entropy에서는  -(ti / yi) 가 softmax로 건너가고 softmax를 거꾸로 거스르면 yi - ti가 나옵니다.\n",
    "        # ti는 i번째 label - true, false\n",
    "        layers = list(self.layers.values()) # 딕셔너리 형태의 layers의 value만 꺼내서 layer로 지정\n",
    "        layers.reverse()# gradient는 거스르는 과정이므로 reverse를 하여 순서를 180도로 뒤집습니다.\n",
    "        for layer in layers: # 각 layer에 대하여\n",
    "            dout = layer.backward(dout) # 각 layer 클래스의 backward함수를 수행하여 역전파를 구합니다.\n",
    "            # 이과정에서 dout이 업데이트 되면서 이전 레이어의 backpropagation의 인풋으로 사용됩니다.\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        # 네트워크 구성도\n",
    "        # | conv 1 | - | relu 1 | - | pool1 | - | fclayer1| - | relu2 | - | fclayer2 | \n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db # 첫번째 convolution의 gradient결과 각각 필터와 편향\n",
    "        grads['W2'], grads['b2'] = self.layers['FClayer1'].dW, self.layers['FClayer1'].db # 첫번째 fclayer1의 gradient결과 각각 필터와 편향\n",
    "        grads['W3'], grads['b3'] = self.layers['FClayer2'].dW, self.layers['FClayer2'].db # 첫번째 fclayer2의 gradient결과 각각 필터와 편향\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T06:55:20.334140Z",
     "start_time": "2020-06-07T06:55:20.301677Z"
    }
   },
   "outputs": [],
   "source": [
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 3, 'filter_size': 3, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=16, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습이 되기전 conv layer 의 파라미터값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALIAAABFCAYAAADuHbzJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAACXklEQVR4nO3dvWpiURSG4W9PprCRNEcDphixS5EmWHkH9ilyDVFIYyukSptAriK3EVImnWIniEKKCZjCfk0zwhRJIcv5+3if9rjX2QdeD1bbEhEC/ndf/vYGgH0gZFggZFggZFggZFggZFj4usuHq6qKdruduuF6vU6t35rP5+kZEVEkqV6vR1VVqVmllPR+JKlWq6VnzGazt4hoHB4eRrPZTM1aLBbp/UjS0dFResZqtXqLiMZH13YKud1u6/n5ObWZh4eH1Pqti4uLvcyRpKqqdH19nZpxcHCwl72cnJykZ3S73YUkNZtN3d7epmZdXl6m9yNJV1dX6Rmj0ejTbxU/LWCBkGGBkGGBkGGBkGGBkGGBkGGBkGGBkGGBkGGBkGGBkGGBkGGBkGGh7HIcwNnZWTw9PaVuOJ1OU+u3Hh8fU+vv7u60XC6LJJVS0mci3N/fZ0dIkt7f39MzxuPxS0R09/Fc+zouYjKZpGecnp6+RET3o2u8kWGBkGGBkGGBkGGBkGGBkGGBkGGBkGGBkGGBkGGBkGGBkGGBkGGBkGGBkGGBkGGBkGFhp4O+X19fdXNzk7rhZrNJrd/qdDqp9b+eMN9qtTQYDFLzjo+PU+u3hsNhesZ4PJYkNRoNnZ+fp2b1er30fiSp3+/vZc5neCPDAiHDAiHDAiHDAiHDAiHDAiHDAiHDAiHDAiHDAiHDAiHDAiHDAiHDAiHDAiHDwk5/vVBK+S5p8fu280d9i4iGZPdc0s9nc32ujy7sFDLwr+KnBSwQMiwQMiwQMiwQMiwQMiwQMiwQMiwQMiz8AIf+eqd4Dm/OAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_pool' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-724999256988>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mx_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-66b08e6b6d71>\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# gradient는 거스르는 과정이므로 reverse를 하여 순서를 180도로 뒤집습니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# 각 layer에 대하여\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0mdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 각 layer 클래스의 backward함수를 수행하여 역전파를 구합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;31m# 이과정에서 dout이 업데이트 되면서 이전 레이어의 backpropagation의 인풋으로 사용됩니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-0ad7383d6c1a>\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, dout)\u001b[0m\n\u001b[0;32m     49\u001b[0m                         \u001b[0mscan_for_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool_w\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# 인풋에서 마스킹 할 구역\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_pool\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscan_for_mask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m   \u001b[1;31m# 마스킹 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                         \u001b[0mdx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool_w\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mmask\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# 필터링\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_pool' is not defined"
     ]
    }
   ],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 100   # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "test_acc_list = []\n",
    "epochs = 3\n",
    "step = int(train_size / batch_size)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx in range(step):\n",
    "        print(batch_idx)\n",
    "        x_batch = x_train[batch_idx*batch_size:batch_idx*batch_size+batch_size]\n",
    "        y_batch = y_train[batch_idx*batch_size:batch_idx*batch_size+batch_size]\n",
    "        grad = network.gradient(x_batch, y_batch)\n",
    "\n",
    "\n",
    "        # 매개변수 갱신\n",
    "        for key in network.params.keys():\n",
    "            network.params[key] -= learning_rate * grad[key]\n",
    "\n",
    "        # 학습 경과 기록\n",
    "        loss = network.loss(x_batch, y_batch)\n",
    "\n",
    "    test_acc = network.accuracy(x_test, y_test)\n",
    "    print(\" test acc | \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 후 파라미터 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALIAAABFCAYAAADuHbzJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAACZklEQVR4nO3cu2piYRSG4eUwhY0gohBEGEEQArZa2+QiJLVXYGWsRVJYWNuJpZ2FhXcgtjZ2NhqYiAcsUgj/FDM7TBFhZDmnj/ephO1a+9/hRSySxEIIBvzvPv3tAwC3QMiQQMiQQMiQQMiQQMiQ8PmaNyeTyZDNZl033G63rvlIPB53n+N0OsXMzNLpdMjn8659u93ONR95e3tz71iv168hhEwqlQq5XM6163A4uM9jZpZIJNw7FovFawgh89G1q0LOZrM2GAxchxkOh675SLFYdM0/Pz+/v87n8zafz137RqORaz6yXC7dO1qt1srMLJfL2Xg8du2aTCbu85iZVatV9477+/vVpWt8tYAEQoYEQoYEQoYEQoYEQoYEQoYEQoYEQoYEQoYEQoYEQoYEQoYEQoaEq36N83g82nQ6dd2w1+u55iO1Ws01fzqd3l+/vLxYp9Nx7Xt6enLNRyqVyk32mJltNhtrt9uuHf1+/yZn6Xa7N9lzCZ/IkEDIkEDIkEDIkEDIkEDIkEDIkEDIkEDIkEDIkEDIkEDIkEDIkEDIkEDIkEDIkEDIkHDVX4jc3d1Zs9l03bBQKLjmI6lUyjX/8z/2Pp/Ptt/vXfseHh5c85FSqeTeMZvNzOz7z+jx8dG1q1wuu89jZlav1907Go3GxWt8IkMCIUMCIUMCIUMCIUMCIUMCIUMCIUMCIUMCIUMCIUMCIUMCIUMCIUMCIUMCIUNCLITw62+Oxb6a2er3HeeP+hJCyJjJPZfZj2dTfa6PLlwVMvCv4qsFJBAyJBAyJBAyJBAyJBAyJBAyJBAyJBAyJHwDzeR9XRmGj8kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################################################################\n",
    "#  2-4 학습된 필터를 캡처하여 제출하세요                                      #\n",
    "######################################################################\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
